Lets start with a brief introduction to Linear Regression and give some important definations then we will implement the Linear Regression two ways as usual, Sklearn version and form scratch version and we will compare each of them in terms of time and cost.

4) Linear Regression:

   1. Definitions:
      1. What is Linear Regression?
         - Linear regression is a fundamental supervised learning algorithm used to model the relationship between a dependent variable (target) and one or more 
           independent variables (features). It assumes that this relationship is linear. In another words, the target can be approximated by a straight line (in 
           higher dimensions, a hyperplane).
         - Simple linear regression models one feature:
                                                 ğ‘¦ = w0 + w1ğ‘¥
           Multiple linear regression models multiple features:
                                       ğ‘¦ = w0 + w1ğ‘¥1 + w2ğ‘¥2 + â‹¯ + wnğ‘¥n
   2. Setup:
      - Given:
        â” A training dataset of ğ‘› examples (instances).
      - Each example:
        â” Comes as a pair of input and output:
                                        (ğ‘¥ğ‘– ,ğ‘¦ğ‘–)
        ğ‘¥ğ‘– : the input (like features or conditions)
        ğ‘¦ğ‘– : the output (the result we want to predict)
      - ğ‘¥ğ‘– is a vector with d attributes:
        â” This means each input ğ‘¥ğ‘– could have many features (not just one!).
      - ğ‘¦ğ‘– âˆˆ R:
        â” Each output is a real number (not a category or class).
    3. Goal:
       - The goal is predicting a continous values by learning  the parameters ğœƒ (theta).
       - Training Phase:
         â” You use the inputs (ğ‘¥1 , â€¦,ğ‘¥ğ‘›) and outputs (ğ‘¦1 , â€¦, ğ‘¦ğ‘›).
         â” You feed them into a Learning Algorithm.
         â” The algorithm learns and produces the parameters ğœƒ (theta).
         â” After training, your prediction function looks like:
                                    f(ğ‘¥) = ğœƒ + ğœƒ1ğ‘¥1 + ğœƒ2ğ‘¥2 + â‹¯ + ğœƒnğ‘¥n
            - where:
              - ğœƒ is the bias term (intercept).
              - ğœƒ1, ğœƒ2, â€¦, ğœƒğ‘› are the weights for each feature.
       - Validation / Prediction Phase:
         â” Now you are given new unseen inputs:
                                     ğ‘¥n+1, ğ‘¥n+2, â€¦
         â” Use the learned parameters ğœƒ and your Prediction Machine to compute:
                                 ğ‘¦^n+1, ğ‘¦^n+2, â€¦
            - where:
              - ğ‘¦^ are the predicted outputs (using the trained model).
          
                


â€‹

           
           
            
           
         
â€‹



















